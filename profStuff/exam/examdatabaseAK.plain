Third QUIZ: CS4472A Tuesday, 5 December 2017, 7:10 pm, Room MC17

NAME AS APPEARS ON STUDENT ID:

STUDENT ID NUMBER:

UWO/CONFLUENCE USER NAME:

REMINDERS:
** (from course outline) The quiz is closed book, 
   closed notes, with no electronic devices allowed, with particular 
   reference to any electronic devices that are capable of communication 
   and/or storing information.

** Write neatly.  If the marker can't read it, it is wrong.

** This quiz shouldn't take long to write.  On the other hand, time
   will pass.  It is a 30 minute quiz with 20 questions.  If you complete 
   a question every  minute you will still have 10 minutes at the end to 
   double check that everything is in order.

** While you are not allowed to open the exam booklet until the
   proctor says you can, you can fill out the information on the cover
   page.  You should also get out your student id and make sure your
   pencils and pens are in order.  If you need to get something out of
   your jacket or knapsack once the exam has started, raise your hand
   and wait til a proctor comes to you to oversee the matter.

QUESTION 1: Amanda Laucher gave an interesting talk on Types vs Tests.
Her view was that whether you used a type or a test to check some
property of a program depended on the kind of property involved. If the
property was that something specific exists, then you would ensure this
with ANSWER
ANSWER=

QUESTION 2: In the talk Cucumbers Have Layers, A Love Story, it was
advocated that one do BDD testing with both cucumber and rspec on the
same project. The role of cucumber would be to provide the customer
ANSWER tests and the role of rspec would be to provide the unit tests
ANSWER=

QUESTION 3: Sandi Metz's approach to unit testing of objects also
distinguishes two types of messages: command and ANSWER
ANSWER=

QUESTION 4: An important concept we will look at related to the question
of when has one done enough testing is ANSWER
ANSWER=

QUESTION 5: An important assumption in testing is that although any
particular program failure may result from a complex sequence of events,
there is generally a first event that if it hadn't gone wrong the failure
wouldn't have occurred. Thus it is sufficient to test for these simple
event failures rather than having to build tests targetted at complicated
interaction failures. This effect is called ANSWER
ANSWER=

QUESTION 6: The protocols for practice expect that the longest amount of
time that you will practice before recording a note is ANSWER
ANSWER=

QUESTION 7: RSpec specifications are sometimes called ANSWER
documentation
ANSWER=

QUESTION 8: The D in SOLID stands for ANSWER
ANSWER=

QUESTION 9: In Confident Code, Avi Grimm presented techniques for
refactoring code to improve its readability, i.e., narrative structure.
One approach is to replace usages of nil with a special ANSWER that
responds to messages by just returning itself. This means method
invocations can be pipelined with constant checks that the previous stage
didn't produce a nil.
ANSWER=

QUESTION 10: One study of 198 user major failure reports on 5 widely used
distributed systems found statement coverage testing could have caught
nearly ANSWER of the causes.
ANSWER=

QUESTION 11: In the discussion of extreme programming, one core
practiceof interest was ANSWER. It was claimed that it produced better
code quicker, most programmers were happy with it, and it help distribute
project information across the team.
ANSWER=

QUESTION 12: The first testing framework for Ruby that we are looking at
is called ANSWER
ANSWER=

QUESTION 13: The differences between RSpec and Cucumber result from the
intent that Cucumber test files are meant to be readable by ANSWER
ANSWER=

QUESTION 14: The TDD Cycle is ANSWER
ANSWER=

QUESTION 15: The S in Solid stands for ANSWER
ANSWER=

QUESTION 16: It is easy to make up test inputs, but it can be tricky to
know what the right output for a given input should be. This is refered
to as the ANSWER problem
ANSWER=

QUESTION 17: Defect causal analysis involves the following steps: select
problem sample, classify selected problems, identify systematic errors,
ANSWER, develop action proposals, and document meeting results
ANSWER=

QUESTION 18: Amanda Laucher gave an interesting talk on Types vs Tests.
Her view was that whether you used a type or a test to check some
property of a program depended on the kind of property involved. If the
property was that something always had a certain quality, then you would
ensure this with ANSWER
ANSWER=

QUESTION 19: The four phases of testing (according to Whittaker) are: 1)
modeling the software environment, 2) selecting test cases, 3) running
and checking test cases, and 4) ANSWER
ANSWER=

QUESTION 20: One study of 100 large open source Java programs compared
better code coverage with number of post-release defect reports and found
ANSWER
ANSWER=

QUESTION 21: If we are mocking a third party API, this can cause the
problem that ANSWER
ANSWER=

QUESTION 22: In the Testing Maturity Model, at Level 5, we aim at ANSWER
rather than defect detection
ANSWER=

QUESTION 23: Testing is generally about finding errors that have already
been made. This course also covers the topic of ANSWER, which is about
trying to prevent errors from being made in the first place.
ANSWER=

QUESTION 24: When testing, it is important to realize that the program
that is being tested is not some random piece of code generated by a room
of monkeys with keyboards, but rather than it is probably pretty close to
being correct. This assumption is called ANSWER
ANSWER=

QUESTION 25: The per cent of the total mark allocated for all the weekly
practices is ANSWER
ANSWER=

QUESTION 26: The motivation behind multiple merges per day per developer
is to ANSWER
ANSWER=

QUESTION 27: When multiple methods of a class have the same parameters,
that generally indicates that those parameters should ANSWER
ANSWER=

QUESTION 28: Sandi Metz approaches unit testing of an object by first
distinquishing among three different message origins: incoming, outgoing,
and ANSWER
ANSWER=

QUESTION 29: Modified condition/decision coverage is often a requirement
(regulatory or contractual) in ANSWER
ANSWER=

QUESTION 30: Using combinatorial testing, if I have 10 binary inputs, I
only need to use ANSWER test cases (each a setting of each of the 10
inputs) to expect to find 98 per cent of the errors in the program.
ANSWER=

QUESTION 31: MicroTest (MiniTest subset)'s usage pattern is for the test
class to inherit from Test so that Class.inherited can be used to ANSWER
ANSWER=

QUESTION 32: In Confident Code, there was a general advocacy of
minimizing the use of if. It was claimed that this helps testing because
ANSWER.
ANSWER=

QUESTION 33: The pattern where you create an object whose job is to
create other objects (rather than using new to create other objects) is
called ANSWER
ANSWER=

QUESTION 34: The number of weekly practices that CS4472 will have this
semester is ANSWER
ANSWER=

QUESTION 35: The four requirements of MC/DC are: 1) each entry and exit
point is invoked, 2) each decision takes every possible outcome, 3) each
condition in a decision takes every possible outcome, and 4) ANSWER
ANSWER=

QUESTION 36: The per cent of the total mark allocated for all the
practice reviews is ANSWER
ANSWER=

QUESTION 37: Unlike MiniTest which is implemented as a class library,
RSpec is implemented in Ruby as an ANSWER
ANSWER=

QUESTION 38: One study of 198 user major failure reports on 5 widely used
distributed systems found that nearly all failures were caused by coding
mistakes in ANSWER
ANSWER=

QUESTION 39: MicroTest (MiniTest subset) uses public_instance_methods to
ANSWER
ANSWER=

QUESTION 40: Amanda Laucher gave an interesting talk on Types vs Tests.
She seemed to indicate that one of the reasons we do so much testing is
because the type systems in the languages we use (such as Java) are not
expressive enough. Although she mentioned many languages that were
experimental research sort of languages; she mentioned ANSWER as the
common language for people who are really into types.
ANSWER=

QUESTION 41: The total amount of practice time you can get credit for
during a practice week is ANSWER
ANSWER=

QUESTION 42: In defect causal analysis, the information you are trying to
extract from the problem reports in order to classify them are: when the
defect that caused the problem was inserted into the software; when the
problem was detected; and ANSWER
ANSWER=

QUESTION 43: Although we often think of programs as taking inputs and
producing outputs, a higher level view of what is going on is to think of
the programs as ANSWER about how to take inputs and produce outputs.
ANSWER=

QUESTION 44: The number of practice reviews that CS4472 will have this
semester is ANSWER
ANSWER=

QUESTION 45: MicroTest (MiniTest subset) discourages the writing of tests
that depend on side-effects of the previous test by ANSWER
ANSWER=

QUESTION 46: The kind of testing we do to make sure that when we change a
program we do not break something that used to work is called ANSWER
ANSWER=

QUESTION 47: When using the Ruby DSL for dynamic types, one can use
builtin types like Num, but one can also define one's own types, like
Even that requires a value of that type to be an even number. To do this,
we create a class Even that contains the method ANSWER, which checks to
see if its input parameteris even.
ANSWER=

QUESTION 48: A main theme behind the practice technique advocated in this
class is that in order to improve your programming, ANSWER
ANSWER=

QUESTION 49: To illustrate the relation between testing and software
design, we will look at the programming technique ANSWER
ANSWER=

QUESTION 50: Sandi Metz's approach to unit testing only does three kinds
of tests on three of the six origin-type message categories. She says you
should ``assert the direct public side-effects'' of messages of the
origin-type ANSWER
ANSWER=

QUESTION 51: When developing tasks with the customer, one approach to
what good tasks for the team to undertake look like is covered by the
INVEST acronym. The S stands for small. Before cucumber was developed,
this often meant that such a task was written on ANSWER to make them
quick to read and easy to tack up on a scheduling board.
ANSWER=

QUESTION 52: Sandi Metz's approach to unit testing only does three kinds
of tests on three of the six origin-type message categories. She says you
should ``expect to send'' messages of the origin-type ANSWER
ANSWER=

QUESTION 53: Once RSpec has created a test class, it fills in its
definition by executing the Ruby method ANSWER
ANSWER=

QUESTION 54: We know that if a line of code hasn't been executed by at
least one of our tests, there are major gaps in our testing. However,
missing lines of code are not very common errors for programmers to
actually make. Much more likely is for a programmer to make a typo.
Checking a test suite to see if it can find all typos is the idea behind
ANSWER testing
ANSWER=

QUESTION 55: In our Agile approach to determining what tasks we are to do
for the customer next, the high level information that we want from the
customer is what is the anticipated role in the organization of the
person who would do the task, what is it that they want to do, and ANSWER
ANSWER=

QUESTION 56: The testing technique called boundary value partition starts
with the notion of breaking the space of inputs into ANSWER
ANSWER=

QUESTION 57: While the notation looks odd, in RSpec, ``it'' is actually
implemented in Ruby as an ANSWER
ANSWER=

QUESTION 58: The practice technique advocated in this class is a
modification of the ANSWER
ANSWER=

QUESTION 59: The paper Orthogonal defect classification-a concept for
in-process measurements was an example of people at IBM analyzing records
of defects in order to ANSWER
ANSWER=

QUESTION 60: When considering mocking for tests, we should consider the
reason for the test itself. For example, if we are doing tests to prevent
a bug from returning to the code base, then the amount of reality we need
in the test is ANSWER
ANSWER=

QUESTION 61: When I say that in RSpec, expect x.to eq y, eq an object
that inherits from ANSWER, meeting the requirements of to
ANSWER=

QUESTION 62: The main high level web testing notation that cucumber and
rspec use is ANSWER
ANSWER=

QUESTION 63: When considering mocking for tests, we should consider the
reason for the test itself. For example, if we are doing acceptance tests
for a customer, then mocking is ANSWER
ANSWER=

QUESTION 64: The differences between RSpec and Cucumber result from the
intent that RSpec test files are meant to be readable by ANSWER
ANSWER=

QUESTION 65: Many people have noticed that Ruby doesn't have static types
like Java. However, it is possible to insert type definitions into Ruby
code using the DSL ANSWER
ANSWER=

QUESTION 66: The Capability Maturity Model for US government contractors
distinguishes 5 levels of company software development process. Level 5
is characterized as ANSWER
ANSWER=

QUESTION 67: The scripts that were designed to aid the practice process
assume that you will be uploading a copy of your work to BitBucket every
time you ANSWER
ANSWER=

QUESTION 68: The number of quizzes CS4472 will have this semester is
ANSWER
ANSWER=

QUESTION 69: According to Michael Feathers, code that is difficult to
test is ANSWER
ANSWER=

QUESTION 70: RSpec and Cucumber are tools designed to support the ANSWER
style of software development
ANSWER=

QUESTION 71: The logs of the practice tasks are supposed to provide a
basis for improving your process. A major way to operationalize such
improvement is to generate a checklist of things to pay more attention to
in the future. We saw an example of how to build such checklists when
looking at how software companies improve their ANSWER process
ANSWER=

QUESTION 72: The I in SOLID stands for ANSWER
ANSWER=

QUESTION 73: Sandi Metz's approach to unit testing only does three kinds
of tests on three of the six origin-type message categories. She says you
should ``assert the result'' on messages of the origin-type ANSWER
ANSWER=

QUESTION 74: The per cent of the total mark allocated for all the quizzes
is ANSWER
ANSWER=

QUESTION 75: According to Robert Martin who first promoted the SOLID
methodology, the S doesn't refer to functions, but to ANSWER
ANSWER=

QUESTION 76: The first tool for checking code quality for programs
written in Ruby is ANSWER, which is described as a code smell detector.
ANSWER=

QUESTION 77: Any agile team must refine and reflect as it goes along,
ANSWER in its local circumstances
ANSWER=

QUESTION 78: The O in SOLID stands for ANSWER
ANSWER=

QUESTION 79: A common piece of information for people interested in
programmer productivity to track is ANSWER
ANSWER=

QUESTION 80: A study by Ahmed et al found that the probability of errors
in untested code was ANSWER the probability of errors in tested code
ANSWER=

QUESTION 81: The L in SOLID stands for ANSWER
ANSWER=

QUESTION 82: The corporate policy of developers merging their working
copies into the main line of the branch repository several times a day is
called ANSWER
ANSWER=

QUESTION 83: The Confident Code talk discussed many ways to avoid using
nil in code -- which tends to require other pieces of code to worry about
whether they have recieved a nil. In addition to returning an object that
returns itself in response to any message, the other major approach is to
ANSWER
ANSWER=

QUESTION 84: The Capability Maturity Model for US government contractors
distinguishes 5 levels of company software development process. Level 1
is characterized as ANSWER
ANSWER=

QUESTION 85: In the discussion of extreme programming, one core practice
of interest was ANSWER. By this they meant that one should establish
overriding themes for projects that then drive common systems of names
making it easier to find things in the code.
ANSWER=

QUESTION 86: The ANSWER is a method developed by Watt S. Humphrey to help
individuals improve their programming skills based on existing methods
that had been developed to help organizations improve their product
development capabilities.
ANSWER=

QUESTION 87: The most primitive web testing system we talked about in
class was ANSWER
ANSWER=

QUESTION 88: In the discussion of extreme programming, one core practice
that was presented was ANSWER. Here the idea is that projects with few
delivery points often produce last minute ``death marches'' that produce
poor code just to meet the minimal requirements to claim that made the
target. Extreme programming wants to avoid this sort of last minute panic
coding.
ANSWER=

QUESTION 89: Many of the ideas of the Capability Maturity Model were
adapted to individual developers under the name ANSWER
ANSWER=

QUESTION 90: The version of Agile that we looked at in class and that
lead to the development of cucumber envisions interacting with the
customer in a structured way through the discussion of ANSWER
ANSWER=

QUESTION 91: When considering mocking for tests, we should consider the
reason for the test itself. For example, if we are doing acceptance tests
for a customer, then mocking is ANSWER
ANSWER=

QUESTION 92: In The Principles Behind the Agile Manifesto, the overriding
theme is to satisfy the customer through ANSWER
ANSWER=

QUESTION 93: Structural testing is another name for ANSWER
ANSWER=

QUESTION 94: When developing tasks with the customer, one approach to
what good tasks for the team to undertake look like is covered by the
INVEST acronym. The I stands for independent. This means that a task
shouldn't depend on ANSWER
ANSWER=

QUESTION 95: In MiniTest, we write test classes that inherit from Test,
but in RSpec these test classes are actually being created at runtime by
ANSWER
ANSWER=

QUESTION 96: When multiple methods of a class have the same parameters,
this is a code smell called ANSWER
ANSWER=

exam_database_file= examdatabase.json
exam_format= plain
dump_database= false
line_width= 72
question_count= 173
create_exam= false
answer_key= true
sample_seed= 222
shuffle_seed= 2345
["C1", "C10", "C2", "C3", "C4", "C5", "C6", "C7", "C8", "C9"]
["C1", "C10", "C2", "C3", "C4", "C5", "C6", "C7", "C8", "C9"]
---------------

ANSWER 1= a test

ANSWER 2= acceptance

ANSWER 3= query

ANSWER 4= coverage
ANSWER 4= mutation

ANSWER 5= the coupling effect

ANSWER 6= 30 minutes

ANSWER 7= executable

ANSWER 8= dependency inversion principle

ANSWER 9= Null Object

ANSWER 10= a quarter
ANSWER 10= 25 per cent
ANSWER 10= 23 per cent

ANSWER 11= pair programming.

ANSWER 12= minitest

ANSWER 13= the customer and the programmer

ANSWER 14= Red Green Refactor

ANSWER 15= single responsibility principle

ANSWER 16= Oracle

ANSWER 17= determine principal cause

ANSWER 18= a type

ANSWER 19= checking how well the testing is going

ANSWER 20= no connection

ANSWER 21= the third party API might change and the change not be reflected in the tests

ANSWER 22= defect prevention

ANSWER 23= quality assurance

ANSWER 24= the competant programmer hypothesis

ANSWER 25= 30

ANSWER 26= minimize merge conflicts

ANSWER 27= be put into a class of their own

ANSWER 28= sent to self

ANSWER 29= safety-critical applications
ANSWER 29= avonic systems
ANSWER 29= automotive systems

ANSWER 30= 13

ANSWER 31= get a list of test classes

ANSWER 32= there are fewer paths that have to be covered
ANSWER 32= there are fewer paths to test

ANSWER 33= the factory pattern

ANSWER 34= 10

ANSWER 35= each condition in a decision is shown to independently affect the outcome of a decision

ANSWER 36= 49

ANSWER 37= domain-specific language
ANSWER 37= DSL

ANSWER 38= the error handling code

ANSWER 39= find methods that begin test\_

ANSWER 40= Haskell

ANSWER 41= 3 hours

ANSWER 42= what type of mistake was made
ANSWER 42= what type of defect was introduced

ANSWER 43= encode knowledge

ANSWER 44= 4

ANSWER 45= running tests in random order

ANSWER 46= regression testing

ANSWER 47= valid?

ANSWER 48= you need data about your past programming

ANSWER 49= test driven development

ANSWER 50= incoming command

ANSWER 51= an index card

ANSWER 52= outgoing command

ANSWER 53= module_exec

ANSWER 54= mutation

ANSWER 55= what benefit they expect to get from the task
ANSWER 55= what reward they expect to get from the task

ANSWER 56= regions of interest

ANSWER 57= method

ANSWER 58= Personal Software Process

ANSWER 59= improve their process

ANSWER 60= only enough to reproduce the bug

ANSWER 61= Matcher

ANSWER 62= capybara

ANSWER 63= not appropriate

ANSWER 64= just the programmer

ANSWER 65= contracts

ANSWER 66= continually improving

ANSWER 67= record a note about your practice progress

ANSWER 68= 3

ANSWER 69= poorly designed

ANSWER 70= Behavior-driven development
ANSWER 70= BDD

ANSWER 71= code review

ANSWER 72= interface segregation principle

ANSWER 73= incoming query

ANSWER 74= 21

ANSWER 75= roles in the business that uses the software

ANSWER 76= reek

ANSWER 77= constantly improving its practices

ANSWER 78= open/closed principle

ANSWER 79= time spent
ANSWER 79= number of lines of code written
ANSWER 79= number of defects found

ANSWER 80= twice

ANSWER 81= Liskov substition principle

ANSWER 82= continuous integration

ANSWER 83= raise an error

ANSWER 84= chaotic
ANSWER 84= ad hoc

ANSWER 85= metaphor

ANSWER 86= Personal Software Process

ANSWER 87= selenium
ANSWER 87= selenium webdriver

ANSWER 88= sustainable pace

ANSWER 89= Personal Software Process

ANSWER 90= user stories

ANSWER 91= not appropriate

ANSWER 92= early and continuous delivery of valuable software

ANSWER 93= code-based testing
ANSWER 93= white-box testing

ANSWER 94= other tasks

ANSWER 95= describe

ANSWER 96= data clumping
